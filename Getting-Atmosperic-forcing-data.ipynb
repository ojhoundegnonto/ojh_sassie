{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eb00fef",
   "metadata": {},
   "source": [
    "# Needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e345540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.8 ms, sys: 29.8 ms, total: 78.6 ms\n",
      "Wall time: 187 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# STEP 1\n",
    "import sys\n",
    "import json\n",
    "import urllib3\n",
    "import certifi\n",
    "import requests\n",
    "from time import sleep\n",
    "from http.cookiejar import CookieJar\n",
    "import urllib.request\n",
    "from urllib.parse import urlencode\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3366dffe",
   "metadata": {},
   "source": [
    "The second step is to initialize the urllib PoolManager and set the base URL for the API requests that will be sent to the GES DISC subsetting service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3805ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2\n",
    "# Create a urllib PoolManager instance to make requests.\n",
    "http = urllib3.PoolManager(cert_reqs='CERT_REQUIRED',ca_certs=certifi.where())\n",
    "# Set the URL for the GES DISC subset service endpoint\n",
    "url = 'https://disc.gsfc.nasa.gov/service/subset/jsonwsp'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b74922",
   "metadata": {},
   "source": [
    "The third step defines a local general-purpose method that submits a JSON-formatted Web Services Protocol (WSP) request to the GES DISC server, checks for any errors, and then returns the response. This method is created for convenience as this task will be repeated more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2669100d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3\n",
    "# This method POSTs formatted JSON WSP requests to the GES DISC endpoint URL\n",
    "# It is created for convenience since this task will be repeated more than once\n",
    "def get_http_data(request):\n",
    "    hdrs = {'Content-Type': 'application/json',\n",
    "            'Accept'      : 'application/json'}\n",
    "    data = json.dumps(request)       \n",
    "    r = http.request('POST', url, body=data, headers=hdrs)\n",
    "    response = json.loads(r.data)   \n",
    "    # Check for errors\n",
    "    if response['type'] == 'jsonwsp/fault' :\n",
    "        print('API Error: faulty %s request' % response['methodname'])\n",
    "        sys.exit(1)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c1b833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4\n",
    "# Define the parameters for the data subset\n",
    "product = 'M2I3NPASM_V5.12.4' #<=========== I have to change here\n",
    "varNames =['T', 'RH', 'O3']   #<=========== I have to change here\n",
    "minlon = -180                 #<=========== I have to change here\n",
    "maxlon = 180                  #<=========== I have to change here\n",
    "minlat = -90                  #<=========== I have to change here\n",
    "maxlat = -45                  #<=========== I have to change here\n",
    "begTime = '1980-01-01'        #<=========== I have to change here\n",
    "endTime = '1980-01-05'        #<=========== I have to change here\n",
    "begHour = '00:00'             #<=========== I have to change here\n",
    "endHour = '00:00'             #<=========== I have to change here\n",
    "#-----------------------------------------------------------------------------#\n",
    "# Subset only the mandatory pressure levels (units are hPa)\n",
    "# 1000 925 850 700 500 400 300 250 200 150 100 70 50 30 20 10 7 5 3 2 1 \n",
    "dimName = 'lev'\n",
    "dimVals = [1,4,7,13,17,19,21,22,23,24,25,26,27,29,30,31,32,33,35,36,37]\n",
    "# Construct the list of dimension name:value pairs to specify the desired subset\n",
    "dimSlice = []\n",
    "for i in range(len(dimVals)):\n",
    "    dimSlice.append({'dimensionId': dimName, 'dimensionValue': dimVals[i]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a33ba2f",
   "metadata": {},
   "source": [
    "\n",
    "``https://goldsmr4.gesdisc.eosdis.nasa.gov/opendap/MERRA2/M2I1NXASM.5.12.4/${yr}/${mn}/MERRA2_${id}.inst1_2d_asm_Nx.${yr}${mn}${dy}.nc4.nc4?QV2M,SLP,T2M,U10M,V10M,time,lat,lon``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0c7ad11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4\n",
    "# Define the parameters for the data subset\n",
    "b           #<=========== I have to change here\n",
    "#-----------------------------------------------------------------------------#\n",
    "# Subset only the mandatory pressure levels (units are hPa)\n",
    "# 1000 925 850 700 500 400 300 250 200 150 100 70 50 30 20 10 7 5 3 2 1 \n",
    "#dimName = 'lev'\n",
    "#dimVals = [1,4,7,13,17,19,21,22,23,24,25,26,27,29,30,31,32,33,35,36,37]\n",
    "# Construct the list of dimension name:value pairs to specify the desired subset\n",
    "dimSlice = [0]\n",
    "#for i in range(len(dimVals)):\n",
    "#    dimSlice.append({'dimensionId': dimName, 'dimensionValue': dimVals[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5598b567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5\n",
    "# Construct JSON WSP request for API method: subset\n",
    "subset_request = {\n",
    "    'methodname': 'subset',\n",
    "    'type': 'jsonwsp/request',\n",
    "    'version': '1.0',\n",
    "    'args': {\n",
    "        'role'  : 'subset',\n",
    "        'start' : begTime,\n",
    "        'end'   : endTime,\n",
    "        'box'   : [minlon, minlat, maxlon, maxlat],\n",
    "        'crop'  : True, \n",
    "        'data': [{'datasetId': product,\n",
    "                  'variable' : varNames[0],\n",
    "                  'slice': dimSlice\n",
    "                 },\n",
    "                 {'datasetId': product,\n",
    "                  'variable' : varNames[1],\n",
    "                  'slice'    : dimSlice\n",
    "                 },\n",
    "                 {'datasetId': product,\n",
    "                  'variable' : varNames[2],\n",
    "                  'slice': dimSlice\n",
    "                 }]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ced20490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5\n",
    "# Construct JSON WSP request for API method: subset\n",
    "subset_request = {\n",
    "    'methodname': 'subset',\n",
    "    'type': 'jsonwsp/request',\n",
    "    'version': '1.0',\n",
    "    'args': {\n",
    "        'role'  : 'subset',\n",
    "        'start' : begTime,\n",
    "        'end'   : endTime,\n",
    "        'box'   : [minlon, minlat, maxlon, maxlat],\n",
    "        'crop'  : True, \n",
    "        'data': [{'datasetId': product,\n",
    "                  'variable' : varNames[0]\n",
    "                 },\n",
    "                 {'datasetId': product,\n",
    "                  'variable' : varNames[1]\n",
    "                 },\n",
    "                 {'datasetId': product,\n",
    "                  'variable' : varNames[2]\n",
    "                 }]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19e4e7c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: 6536a84103a4d7149a3bd92d\n",
      "Job status: Accepted\n"
     ]
    }
   ],
   "source": [
    "# STEP 6\n",
    "# Submit the subset request to the GES DISC Server\n",
    "response = get_http_data(subset_request)\n",
    "# Report the JobID and initial status\n",
    "myJobId = response['result']['jobId']\n",
    "print('Job ID: '+myJobId)\n",
    "print('Job status: '+response['result']['Status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dfb656",
   "metadata": {},
   "source": [
    "At this point the job is running on the GES DISC server. The seventh step is to construct another JSON WSP status_request, with methodname parameter set to 'GetStatus'. The args parameter contains the extracted Job ID. The status_request is submitted periodically to monitor the job status as it changes from 'Accepted' to 'Running' to '100% completed'. When the job is finished check on the final status to ensure the job succeeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "420bc0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: Succeeded (100% complete)\n",
      "Job Finished:  Complete (M2I3NPASM_5.12.4)\n"
     ]
    }
   ],
   "source": [
    "# STEP 7\n",
    "# Construct JSON WSP request for API method: GetStatus\n",
    "status_request = {\n",
    "    'methodname': 'GetStatus',\n",
    "    'version': '1.0',\n",
    "    'type': 'jsonwsp/request',\n",
    "    'args': {'jobId': myJobId}\n",
    "}\n",
    "\n",
    "# Check on the job status after a brief nap\n",
    "while response['result']['Status'] in ['Accepted', 'Running']:\n",
    "    sleep(5)\n",
    "    response = get_http_data(status_request)\n",
    "    status  = response['result']['Status']\n",
    "    percent = response['result']['PercentCompleted']\n",
    "    print ('Job status: %s (%d%c complete)' % (status,percent,'%'))\n",
    "if response['result']['Status'] == 'Succeeded' :\n",
    "    print ('Job Finished:  %s' % response['result']['message'])\n",
    "else : \n",
    "    print('Job Failed: %s' % response['fault']['code'])\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d455ef5",
   "metadata": {},
   "source": [
    "After confirming that the job has finished successfully it is time to retrieve the results. The results of a subset request job are URLs: there are HTTP_Services URLs (one for every data granule in the time range of interest) plus links to any relevant documentation. Each HTTP_Services URL contains the specifics of the subset request encoded as facets. Data subsets and documentation files are downloaded using the requests Python library.\n",
    "\n",
    "There are two ways to retrieve the list of URLs when the subset job is finished:\n",
    "\n",
    "**Method 1:** Use the API method named GetResult. This method will return the URLs along with three additional attributes: a label, plus the beginning and ending time stamps for that particular data granule. The label serves as the filename for the downloaded subsets.\n",
    "\n",
    "**Method 2:** Retrieve a plain-text list of URLs in a single shot using the saved JobID. This is a shortcut to retrieve just the list of URLs without any of the other metadata.\n",
    "\n",
    "The next step for **Method 1** is to construct a third type of JSON WSP request that retrieves the results of this Job. When that request is submitted the results are returned in batches of 20 items, starting with item 0. The startIndex value in the results_request structure must be updated after each successive batch is retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9c87503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 6 out of 6 expected items\n"
     ]
    }
   ],
   "source": [
    "# STEP 8 (Plan A - preferred)\n",
    "# Construct JSON WSP request for API method: GetResult\n",
    "batchsize = 20\n",
    "results_request = {\n",
    "    'methodname': 'GetResult',\n",
    "    'version': '1.0',\n",
    "    'type': 'jsonwsp/request',\n",
    "    'args': {\n",
    "        'jobId': myJobId,\n",
    "        'count': batchsize,\n",
    "        'startIndex': 0\n",
    "    }\n",
    "}\n",
    "\n",
    "# Retrieve the results in JSON in multiple batches \n",
    "# Initialize variables, then submit the first GetResults request\n",
    "# Add the results from this batch to the list and increment the count\n",
    "results = []\n",
    "count = 0 \n",
    "response = get_http_data(results_request) \n",
    "count = count + response['result']['itemsPerPage']\n",
    "results.extend(response['result']['items']) \n",
    "\n",
    "# Increment the startIndex and keep asking for more results until we have them all\n",
    "total = response['result']['totalResults']\n",
    "while count < total :\n",
    "    results_request['args']['startIndex'] += batchsize \n",
    "    response = get_http_data(results_request) \n",
    "    count = count + response['result']['itemsPerPage']\n",
    "    results.extend(response['result']['items'])\n",
    "       \n",
    "# Check on the bookkeeping\n",
    "print('Retrieved %d out of %d expected items' % (len(results), total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a96747",
   "metadata": {},
   "source": [
    "Below is the code for **Method 2**. Construct a request using the saved JobID and retrieve the results with the requests library. If the requests.get() method does not return an error, the URLs are stored locally and printed out for informational purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6beb727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "https://goldsmr5.gesdisc.eosdis.nasa.gov/data/MERRA2/M2I3NPASM.5.12.4/doc/MERRA2.README.pdf\r\n",
      "\n",
      "https://goldsmr5.gesdisc.eosdis.nasa.gov/daac-bin/OTF/HTTP_services.cgi?FILENAME=%2Fdata%2FMERRA2%2FM2I3NPASM.5.12.4%2F1980%2F01%2FMERRA2_100.inst3_3d_asm_Np.19800101.nc4&SHORTNAME=M2I3NPASM&DATASET_VERSION=5.12.4&VARIABLES=T%2CRH%2CO3&VERSION=1.02&BBOX=-90%2C-180%2C-45%2C180&LABEL=MERRA2_100.inst3_3d_asm_Np.19800101.SUB.nc&SERVICE=L34RS_MERRA2&LAYERS=LAYER_1%2C4%2C7%2C13%2C17%2C19%2C21%2C22%2C23%2C24%2C25%2C26%2C27%2C29%2C30%2C31%2C32%2C33%2C35%2C36%2C37&FORMAT=nc4%2F\r\n",
      "\n",
      "https://goldsmr5.gesdisc.eosdis.nasa.gov/daac-bin/OTF/HTTP_services.cgi?FILENAME=%2Fdata%2FMERRA2%2FM2I3NPASM.5.12.4%2F1980%2F01%2FMERRA2_100.inst3_3d_asm_Np.19800102.nc4&SHORTNAME=M2I3NPASM&DATASET_VERSION=5.12.4&VARIABLES=T%2CRH%2CO3&VERSION=1.02&BBOX=-90%2C-180%2C-45%2C180&LABEL=MERRA2_100.inst3_3d_asm_Np.19800102.SUB.nc&SERVICE=L34RS_MERRA2&LAYERS=LAYER_1%2C4%2C7%2C13%2C17%2C19%2C21%2C22%2C23%2C24%2C25%2C26%2C27%2C29%2C30%2C31%2C32%2C33%2C35%2C36%2C37&FORMAT=nc4%2F\r\n",
      "\n",
      "https://goldsmr5.gesdisc.eosdis.nasa.gov/daac-bin/OTF/HTTP_services.cgi?FILENAME=%2Fdata%2FMERRA2%2FM2I3NPASM.5.12.4%2F1980%2F01%2FMERRA2_100.inst3_3d_asm_Np.19800103.nc4&SHORTNAME=M2I3NPASM&DATASET_VERSION=5.12.4&VARIABLES=T%2CRH%2CO3&VERSION=1.02&BBOX=-90%2C-180%2C-45%2C180&LABEL=MERRA2_100.inst3_3d_asm_Np.19800103.SUB.nc&SERVICE=L34RS_MERRA2&LAYERS=LAYER_1%2C4%2C7%2C13%2C17%2C19%2C21%2C22%2C23%2C24%2C25%2C26%2C27%2C29%2C30%2C31%2C32%2C33%2C35%2C36%2C37&FORMAT=nc4%2F\r\n",
      "\n",
      "https://goldsmr5.gesdisc.eosdis.nasa.gov/daac-bin/OTF/HTTP_services.cgi?FILENAME=%2Fdata%2FMERRA2%2FM2I3NPASM.5.12.4%2F1980%2F01%2FMERRA2_100.inst3_3d_asm_Np.19800104.nc4&SHORTNAME=M2I3NPASM&DATASET_VERSION=5.12.4&VARIABLES=T%2CRH%2CO3&VERSION=1.02&BBOX=-90%2C-180%2C-45%2C180&LABEL=MERRA2_100.inst3_3d_asm_Np.19800104.SUB.nc&SERVICE=L34RS_MERRA2&LAYERS=LAYER_1%2C4%2C7%2C13%2C17%2C19%2C21%2C22%2C23%2C24%2C25%2C26%2C27%2C29%2C30%2C31%2C32%2C33%2C35%2C36%2C37&FORMAT=nc4%2F\r\n",
      "\n",
      "https://goldsmr5.gesdisc.eosdis.nasa.gov/daac-bin/OTF/HTTP_services.cgi?FILENAME=%2Fdata%2FMERRA2%2FM2I3NPASM.5.12.4%2F1980%2F01%2FMERRA2_100.inst3_3d_asm_Np.19800105.nc4&SHORTNAME=M2I3NPASM&DATASET_VERSION=5.12.4&VARIABLES=T%2CRH%2CO3&VERSION=1.02&BBOX=-90%2C-180%2C-45%2C180&LABEL=MERRA2_100.inst3_3d_asm_Np.19800105.SUB.nc&SERVICE=L34RS_MERRA2&LAYERS=LAYER_1%2C4%2C7%2C13%2C17%2C19%2C21%2C22%2C23%2C24%2C25%2C26%2C27%2C29%2C30%2C31%2C32%2C33%2C35%2C36%2C37&FORMAT=nc4%2F\n"
     ]
    }
   ],
   "source": [
    "# STEP 8 (Plan B)\n",
    "# Retrieve a plain-text list of results in a single shot using the saved JobID\n",
    "\n",
    "result = requests.get('https://disc.gsfc.nasa.gov/api/jobs/results/'+myJobId)\n",
    "try:\n",
    "    result.raise_for_status()\n",
    "    urls = result.text.split('\\n')\n",
    "    for i in urls : print('\\n%s' % i)\n",
    "except :\n",
    "    print('Request returned error code %d' % result.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7688f4fc",
   "metadata": {},
   "source": [
    "It is important to keep in mind that the results returned at this point are not data files but lists of URLs. Most of the URLs will contain HTTP_Services requests to actually do the subsetting and return the data, but some of them may be links to documentation files pertaining to the dataset in question.\n",
    "\n",
    "It is worthwhile to separate the document URLs from the HTTP_services URLs in case the documentation has already been retrieved so they won't be downloaded again. The way we do this is to check for start and end attributes which are always associated with HTTP_services URLs. The remainder of the example code assumes the use of **Method 1** because it makes use of this extra metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "032ed3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the results into documents and URLs\n",
    "\n",
    "docs = []\n",
    "urls = []\n",
    "for item in results :\n",
    "    try:\n",
    "        if item['start'] and item['end'] : urls.append(item) \n",
    "    except:\n",
    "        docs.append(item)\n",
    "# Print out the documentation links, but do not download them\n",
    "# print('\\nDocumentation:')\n",
    "# for item in docs : print(item['label']+': '+item['link'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008bf77e",
   "metadata": {},
   "source": [
    "The final step is to invoke each HTTP_Services URL and download the data files. The contents of the label attribute are used here as the output file name, but the name can be any string. It is important to download each file one at a time, in series rather than in parallel, to avoid overloading the GES DISC servers.\n",
    "\n",
    "We show two methods for downloading the data files using either the requests.get() or the urllib.request() modules. Use one or the other, but not both. If the requests.get() method fails try the alternate code block, but be sure to update it with a proper Earthdata login name and password.\n",
    "\n",
    "**Download with Requests Library:**  \n",
    "In STEP 10, for the request.get() module to work properly, you must have a [HOME/.netrc](https://disc.gsfc.nasa.gov/data-access) file that contains the following text (configured with your own Earthdata userid and password): machine urs.earthdata.nasa.gov login [userid] password [password]. In the alternate STEP 10, you can provide your userid and password on-the-fly when running the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faa1e657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HTTP_services output:\n",
      "MERRA2_100.inst3_3d_asm_Np.19800101.SUB.nc is downloaded\n",
      "MERRA2_100.inst3_3d_asm_Np.19800102.SUB.nc is downloaded\n",
      "MERRA2_100.inst3_3d_asm_Np.19800103.SUB.nc is downloaded\n",
      "MERRA2_100.inst3_3d_asm_Np.19800104.SUB.nc is downloaded\n",
      "MERRA2_100.inst3_3d_asm_Np.19800105.SUB.nc is downloaded\n",
      "Downloading is done and find the downloaded files in your current working directory\n"
     ]
    }
   ],
   "source": [
    "# STEP 10 \n",
    "# Use the requests library to submit the HTTP_Services URLs and write out the results.\n",
    "print('\\nHTTP_services output:')\n",
    "for item in urls :\n",
    "    URL = item['link'] \n",
    "    result = requests.get(URL)\n",
    "    try:\n",
    "        result.raise_for_status()\n",
    "        outfn = item['label']\n",
    "        f = open(outfn,'wb')\n",
    "        f.write(result.content)\n",
    "        f.close()\n",
    "        print(outfn, \"is downloaded\")\n",
    "    except:\n",
    "        print('Error! Status code is %d for this URL:\\n%s' % (result.status.code,URL))\n",
    "        print('Help for downloading data is at https://disc.gsfc.nasa.gov/data-access')\n",
    "        \n",
    "print('Downloading is done and find the downloaded files in your current working directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a71cb76",
   "metadata": {},
   "source": [
    "**Alternative Download Method Using Native Python:**  \n",
    "If the code above does not work in your local environment try this alternate method. Please enter your Earthdata userid and password when prompted while running the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3de9373c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provide your EarthData userid: ojhoundegnonto2jpl\n",
      "Provide your EarthData password: ········\n",
      "\n",
      "HTTP_services output:\n",
      "MERRA2_100.inst3_3d_asm_Np.19800101.SUB.nc is downloaded\n",
      "MERRA2_100.inst3_3d_asm_Np.19800102.SUB.nc is downloaded\n",
      "MERRA2_100.inst3_3d_asm_Np.19800103.SUB.nc is downloaded\n",
      "MERRA2_100.inst3_3d_asm_Np.19800104.SUB.nc is downloaded\n",
      "MERRA2_100.inst3_3d_asm_Np.19800105.SUB.nc is downloaded\n",
      "Downloading is done and find the downloaded files in your current working directory\n"
     ]
    }
   ],
   "source": [
    "# ATLERNATIVE STEP 10 \n",
    "# Create a password manager to deal with the 401 response that is returned from\n",
    "# Earthdata Login\n",
    "\n",
    "# Create a password manager to deal with the 401 response that is returned from\n",
    "# Earthdata Login\n",
    "\n",
    "username = input(\"Provide your EarthData userid: \")\n",
    "password = getpass.getpass(\"Provide your EarthData password: \")\n",
    "\n",
    "password_manager = urllib.request.HTTPPasswordMgrWithDefaultRealm()\n",
    "password_manager.add_password(None, \"https://urs.earthdata.nasa.gov\", username, password)\n",
    "\n",
    "# Create a cookie jar for storing cookies. This is used to store and return the session cookie #given to use by the data server\n",
    "cookie_jar = CookieJar()\n",
    "   \n",
    "# Install all the handlers.\n",
    "opener = urllib.request.build_opener (urllib.request.HTTPBasicAuthHandler (password_manager),urllib.request.HTTPCookieProcessor (cookie_jar))\n",
    "urllib.request.install_opener(opener)\n",
    " \n",
    "# Open a request for the data, and download files\n",
    "print('\\nHTTP_services output:')\n",
    "for item in urls:\n",
    "    URL = item['link'] \n",
    "    DataRequest = urllib.request.Request(URL)\n",
    "    DataResponse = urllib.request.urlopen(DataRequest)\n",
    "\n",
    "# Print out the result\n",
    "    DataBody = DataResponse.read()\n",
    "\n",
    "# Save file to working directory\n",
    "    try:\n",
    "        file_name = item['label']\n",
    "        file_ = open(file_name, 'wb')\n",
    "        file_.write(DataBody)\n",
    "        file_.close()\n",
    "        print (file_name, \"is downloaded\")\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "         print(e)\n",
    "            \n",
    "print('Downloading is done and find the downloaded files in your current working directory')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1add16",
   "metadata": {},
   "source": [
    "The two code blocks above replace Steps 4 and 5 in the complete workflow outlined in Example #1.\n",
    "\n",
    "**Additional Info:**  \n",
    "[How to Use the Web Services API for Subsetting](https://disc.gsfc.nasa.gov/information/howto?keywords=api&title=How%20to%20Use%20the%20Web%20Services%20API%20for%20Subsetting)  \n",
    "[How to Use the Web Services API for Dataset Searching](https://disc.gsfc.nasa.gov/information/howto?keywords=api&title=How%20to%20Use%20the%20Web%20Services%20API%20for%20Dataset%20Searching)  \n",
    "[Complete reference documentation for the GES DISC Subsetting Service API](https://disc.gsfc.nasa.gov/service/subset) \n",
    "\n",
    "<font size=\"1\">THE SUBJECT FILE IS PROVIDED \"AS IS\" WITHOUT ANY WARRANTY OF ANY KIND, EITHER EXPRESSED, IMPLIED, OR STATUTORY, INCLUDING, BUT NOT LIMITED TO, ANY WARRANTY THAT THE SUBJECT FILE WILL CONFORM TO SPECIFICATIONS, ANY IMPLIED WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE, OR FREEDOM FROM INFRINGEMENT, ANY WARRANTY THAT THE SUBJECT FILE WILL BE ERROR FREE, OR ANY WARRANTY THAT DOCUMENTATION, IF PROVIDED, WILL CONFORM TO THE SUBJECT FILE. THIS AGREEMENT DOES NOT, IN ANY MANNER, CONSTITUTE AN ENDORSEMENT BY GOVERNMENT AGENCY OR ANY PRIOR RECIPIENT OF ANY RESULTS, RESULTING DESIGNS, HARDWARE, SOFTWARE PRODUCTS OR ANY OTHER APPLICATIONS RESULTING FROM USE OF THE SUBJECT FILE. FURTHER, GOVERNMENT AGENCY DISCLAIMS ALL WARRANTIES AND LIABILITIES REGARDING THIRD-PARTY SOFTWARE, IF PRESENT IN THE SUBJECT FILE, AND DISTRIBUTES IT \"AS IS.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3efa7fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = 'M2I1NXASM.5.12.4' #<=========== I have to change here\n",
    "varName ='T10M'   #<=========== I have to change here\n",
    "minlon = -160                 #<=========== I have to change here\n",
    "maxlon = -140                  #<=========== I have to change here\n",
    "minlat = 56                  #<=========== I have to change here\n",
    "maxlat = 75                  #<=========== I have to change here\n",
    "begTime = '2022-09-01'        #<=========== I have to change here\n",
    "endTime = '2022-09-05'        #<=========== I have to change here\n",
    "#begHour = '00:00'             #<=========== I have to change here\n",
    "#endHour = '00:00'  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400fa91f",
   "metadata": {},
   "source": [
    "# STEP 4\n",
    "# Define the parameters for the second subset example\n",
    "product = 'M2T1NXSLV_5.12.4'\n",
    "varNames =['TQV', 'TQL', 'TQI']\n",
    "minlon = -180\n",
    "maxlon = 180\n",
    "minlat = -90\n",
    "maxlat = 90\n",
    "begTime = '1980-01-04'\n",
    "endTime = '1980-01-05'\n",
    "\n",
    "\n",
    "diurnalAggregation = '1'\n",
    "interp = 'remapbil'\n",
    "destGrid = 'cfsr0.5a'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "38bd934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5\n",
    "# Construct JSON WSP request for API method: subset\n",
    "subset_request = {\n",
    "    'methodname': 'subset',\n",
    "    'type': 'jsonwsp/request',\n",
    "    'version': '1.0',\n",
    "    'args': {\n",
    "        'role'  : 'subset',\n",
    "        'start' : begTime,\n",
    "        'end'   : endTime,\n",
    "        'box'   : [minlon, minlat, maxlon, maxlat],\n",
    "        'crop'  : True,\n",
    "        'diurnalAggregation': diurnalAggregation,\n",
    "        'mapping': interp,\n",
    "        'grid'  : destGrid,\n",
    "        'data': [{'datasetId': product,\n",
    "                  'variable' : varNames[0]\n",
    "                 }],\n",
    "                 {'datasetId': product,\n",
    "                  'variable' : varNames[1]\n",
    "                 },\n",
    "                 {'datasetId': product,\n",
    "                  'variable' : varNames[2]\n",
    "                 }]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd14f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#product = 'M2T1NXSLV_5.12.4'\n",
    "#varNames =['TQV', 'TQL', 'TQI']\n",
    "#varName ='TQV'\n",
    "\n",
    "product = 'M2I1NXASM.5.12.4' #<=========== I have to change here\n",
    "#product = 'M2IMNXASM.5.12.4'\n",
    "varName =['T2M','T10M', 'TO3']\n",
    "\n",
    "minlon = -180\n",
    "maxlon = 180\n",
    "minlat = -90\n",
    "maxlat = 90\n",
    "begTime = '2020-01-04'\n",
    "endTime = '2020-01-05'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "de56ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5\n",
    "# Construct JSON WSP request for API method: subset\n",
    "subset_request = {\n",
    "    'methodname': 'subset',\n",
    "    'type': 'jsonwsp/request',\n",
    "    'version': '1.0',\n",
    "    'args': {\n",
    "        'role'  : 'subset',\n",
    "        'start' : begTime,\n",
    "        'end'   : endTime,\n",
    "        'box'   : [minlon, minlat, maxlon, maxlat],\n",
    "        'crop'  : True,        \n",
    "        'data': [{'datasetId': product,\n",
    "                  'variable' : varNames[0]\n",
    "                 },\n",
    "                  {'datasetId': product,\n",
    "                  'variable' : varNames[1]\n",
    "                 },\n",
    "                 {'datasetId': product,\n",
    "                  'variable' : varNames[2]\n",
    "                 }]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cbf27e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5\n",
    "# Construct JSON WSP request for API method: subset\n",
    "subset_request = {\n",
    "    'methodname': 'subset',\n",
    "    'type': 'jsonwsp/request',\n",
    "    'version': '1.0',\n",
    "    'args': {\n",
    "        'role'  : 'subset',\n",
    "        'start' : begTime,\n",
    "        'end'   : endTime,\n",
    "        'box'   : [minlon, minlat, maxlon, maxlat],\n",
    "        'crop'  : True,        \n",
    "        'data': [{'datasetId': product,\n",
    "                  'variable' : varName\n",
    "                 }]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7e996135",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'methodname'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# STEP 6\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Submit the subset request to the GES DISC Server\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_http_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset_request\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Report the JobID and initial status\u001b[39;00m\n\u001b[1;32m      5\u001b[0m myJobId \u001b[38;5;241m=\u001b[39m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjobId\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[3], line 12\u001b[0m, in \u001b[0;36mget_http_data\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Check for errors\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjsonwsp/fault\u001b[39m\u001b[38;5;124m'\u001b[39m :\n\u001b[0;32m---> 12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPI Error: faulty \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m request\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmethodname\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     13\u001b[0m     sys\u001b[38;5;241m.\u001b[39mexit(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[0;31mKeyError\u001b[0m: 'methodname'"
     ]
    }
   ],
   "source": [
    "# STEP 6\n",
    "# Submit the subset request to the GES DISC Server\n",
    "response = get_http_data(subset_request)\n",
    "# Report the JobID and initial status\n",
    "myJobId = response['result']['jobId']\n",
    "print('Job ID: '+myJobId)\n",
    "print('Job status: '+response['result']['Status'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4572d3d",
   "metadata": {},
   "source": [
    "At this point the job is running on the GES DISC server. The seventh step is to construct another JSON WSP status_request, with methodname parameter set to 'GetStatus'. The args parameter contains the extracted Job ID. The status_request is submitted periodically to monitor the job status as it changes from 'Accepted' to 'Running' to '100% completed'. When the job is finished check on the final status to ensure the job succeeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96782f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job status: Succeeded (100% complete)\n",
      "Job Finished:  Complete (M2I3NPASM_5.12.4)\n"
     ]
    }
   ],
   "source": [
    "# STEP 7\n",
    "# Construct JSON WSP request for API method: GetStatus\n",
    "status_request = {\n",
    "    'methodname': 'GetStatus',\n",
    "    'version': '1.0',\n",
    "    'type': 'jsonwsp/request',\n",
    "    'args': {'jobId': myJobId}\n",
    "}\n",
    "\n",
    "# Check on the job status after a brief nap\n",
    "while response['result']['Status'] in ['Accepted', 'Running']:\n",
    "    sleep(5)\n",
    "    response = get_http_data(status_request)\n",
    "    status  = response['result']['Status']\n",
    "    percent = response['result']['PercentCompleted']\n",
    "    print ('Job status: %s (%d%c complete)' % (status,percent,'%'))\n",
    "if response['result']['Status'] == 'Succeeded' :\n",
    "    print ('Job Finished:  %s' % response['result']['message'])\n",
    "else : \n",
    "    print('Job Failed: %s' % response['fault']['code'])\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024acf27",
   "metadata": {},
   "source": [
    "After confirming that the job has finished successfully it is time to retrieve the results. The results of a subset request job are URLs: there are HTTP_Services URLs (one for every data granule in the time range of interest) plus links to any relevant documentation. Each HTTP_Services URL contains the specifics of the subset request encoded as facets. Data subsets and documentation files are downloaded using the requests Python library.\n",
    "\n",
    "There are two ways to retrieve the list of URLs when the subset job is finished:\n",
    "\n",
    "**Method 1:** Use the API method named GetResult. This method will return the URLs along with three additional attributes: a label, plus the beginning and ending time stamps for that particular data granule. The label serves as the filename for the downloaded subsets.\n",
    "\n",
    "**Method 2:** Retrieve a plain-text list of URLs in a single shot using the saved JobID. This is a shortcut to retrieve just the list of URLs without any of the other metadata.\n",
    "\n",
    "The next step for **Method 1** is to construct a third type of JSON WSP request that retrieves the results of this Job. When that request is submitted the results are returned in batches of 20 items, starting with item 0. The startIndex value in the results_request structure must be updated after each successive batch is retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f845997e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 out of 3 expected items\n"
     ]
    }
   ],
   "source": [
    "# STEP 8 (Plan A - preferred)\n",
    "# Construct JSON WSP request for API method: GetResult\n",
    "batchsize = 20\n",
    "results_request = {\n",
    "    'methodname': 'GetResult',\n",
    "    'version': '1.0',\n",
    "    'type': 'jsonwsp/request',\n",
    "    'args': {\n",
    "        'jobId': myJobId,\n",
    "        'count': batchsize,\n",
    "        'startIndex': 0\n",
    "    }\n",
    "}\n",
    "\n",
    "# Retrieve the results in JSON in multiple batches \n",
    "# Initialize variables, then submit the first GetResults request\n",
    "# Add the results from this batch to the list and increment the count\n",
    "results = []\n",
    "count = 0 \n",
    "response = get_http_data(results_request) \n",
    "count = count + response['result']['itemsPerPage']\n",
    "results.extend(response['result']['items']) \n",
    "\n",
    "# Increment the startIndex and keep asking for more results until we have them all\n",
    "total = response['result']['totalResults']\n",
    "while count < total :\n",
    "    results_request['args']['startIndex'] += batchsize \n",
    "    response = get_http_data(results_request) \n",
    "    count = count + response['result']['itemsPerPage']\n",
    "    results.extend(response['result']['items'])\n",
    "       \n",
    "# Check on the bookkeeping\n",
    "print('Retrieved %d out of %d expected items' % (len(results), total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc5e154",
   "metadata": {},
   "source": [
    "It is important to keep in mind that the results returned at this point are not data files but lists of URLs. Most of the URLs will contain HTTP_Services requests to actually do the subsetting and return the data, but some of them may be links to documentation files pertaining to the dataset in question.\n",
    "\n",
    "It is worthwhile to separate the document URLs from the HTTP_services URLs in case the documentation has already been retrieved so they won't be downloaded again. The way we do this is to check for start and end attributes which are always associated with HTTP_services URLs. The remainder of the example code assumes the use of **Method 1** because it makes use of this extra metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "850d5732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the results into documents and URLs\n",
    "\n",
    "docs = []\n",
    "urls = []\n",
    "for item in results :\n",
    "    try:\n",
    "        if item['start'] and item['end'] : urls.append(item) \n",
    "    except:\n",
    "        docs.append(item)\n",
    "# Print out the documentation links, but do not download them\n",
    "# print('\\nDocumentation:')\n",
    "# for item in docs : print(item['label']+': '+item['link'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1105cac",
   "metadata": {},
   "source": [
    "The final step is to invoke each HTTP_Services URL and download the data files. The contents of the label attribute are used here as the output file name, but the name can be any string. It is important to download each file one at a time, in series rather than in parallel, to avoid overloading the GES DISC servers.\n",
    "\n",
    "We show two methods for downloading the data files using either the requests.get() or the urllib.request() modules. Use one or the other, but not both. If the requests.get() method fails try the alternate code block, but be sure to update it with a proper Earthdata login name and password.\n",
    "\n",
    "**Download with Requests Library:**  \n",
    "In STEP 10, for the request.get() module to work properly, you must have a [HOME/.netrc](https://disc.gsfc.nasa.gov/data-access) file that contains the following text (configured with your own Earthdata userid and password): machine urs.earthdata.nasa.gov login [userid] password [password]. In the alternate STEP 10, you can provide your userid and password on-the-fly when running the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2ef80109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HTTP_services output:\n",
      "MERRA2_100.tavg1_2d_slv_Nx.19800104.SUB.nc is downloaded\n",
      "MERRA2_100.tavg1_2d_slv_Nx.19800105.SUB.nc is downloaded\n",
      "Downloading is done and find the downloaded files in your current working directory\n"
     ]
    }
   ],
   "source": [
    "# STEP 10 \n",
    "# Use the requests library to submit the HTTP_Services URLs and write out the results.\n",
    "print('\\nHTTP_services output:')\n",
    "for item in urls :\n",
    "    URL = item['link'] \n",
    "    result = requests.get(URL)\n",
    "    try:\n",
    "        result.raise_for_status()\n",
    "        outfn = item['label']\n",
    "        f = open(outfn,'wb')\n",
    "        f.write(result.content)\n",
    "        f.close()\n",
    "        print(outfn, \"is downloaded\")\n",
    "    except:\n",
    "        print('Error! Status code is %d for this URL:\\n%s' % (result.status.code,URL))\n",
    "        print('Help for downloading data is at https://disc.gsfc.nasa.gov/data-access')\n",
    "        \n",
    "print('Downloading is done and find the downloaded files in your current working directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb1ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
